{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "e2195128-b796-44fd-8edb-beb09941d8fc"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import target_encoding as te\n",
    "import gc\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "import time\n",
    "\n",
    "#Images\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "4cc55424-87d6-4f00-89d9-a51982dd1ff3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file rows and columns are :  (1503424, 18)\n",
      "Test file rows and columns are :  (508438, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/mnt/0d28870f-7d1c-4a10-841a-0195e11cdce3/Jonas/Avito/data/train.csv\", parse_dates=[\"activation_date\"])#, nrows=1000)\n",
    "test_df = pd.read_csv(\"/mnt/0d28870f-7d1c-4a10-841a-0195e11cdce3/Jonas/Avito/data/test.csv\", parse_dates=[\"activation_date\"])#, nrows=1000)\n",
    "trainindex = train_df.index\n",
    "testindex = test_df.index\n",
    "test_id = test_df[\"item_id\"].values\n",
    "print(\"Train file rows and columns are : \", train_df.shape)\n",
    "print(\"Test file rows and columns are : \", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df.deal_probability.copy()\n",
    "train_df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "# Target encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\", \"image_top_1\"]\n",
    "for col in cat_vars:\n",
    "    train_df[col], test_df[col] = te.target_encode(train_df[col], test_df[col], train_y, min_samples_leaf=100, smoothing=10, noise_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Featues\n",
    "cols_to_add = ['width', 'height', 'img_mean_color', 'img_std_color', 'avg_red', 'avg_green', 'avg_blue', 'blurryness']\n",
    "train_df = pd.concat([train_df,pd.DataFrame(columns=cols_to_add)])\n",
    "test_df = pd.concat([test_df,pd.DataFrame(columns=cols_to_add)])\n",
    "train_df[cols_to_add] = train_df[cols_to_add].apply(pd.to_numeric)\n",
    "test_df[cols_to_add] = test_df[cols_to_add].apply(pd.to_numeric)\n",
    "train_df.fillna(0,inplace=True)\n",
    "test_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_date</th>\n",
       "      <th>avg_blue</th>\n",
       "      <th>avg_green</th>\n",
       "      <th>avg_red</th>\n",
       "      <th>blurryness</th>\n",
       "      <th>category_name</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>height</th>\n",
       "      <th>image</th>\n",
       "      <th>...</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>region</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200410</td>\n",
       "      <td>0.121560</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0.140372</td>\n",
       "      <td>0.140869</td>\n",
       "      <td>0.076021</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.121401</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>0.149016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191746</td>\n",
       "      <td>0.141313</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123041</td>\n",
       "      <td>0.140194</td>\n",
       "      <td>0.138528</td>\n",
       "      <td>0.177335</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.138003</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>0.151873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171280</td>\n",
       "      <td>0.126960</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.136329</td>\n",
       "      <td>0.139835</td>\n",
       "      <td>0.176872</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.136797</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>0.149318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197608</td>\n",
       "      <td>0.133087</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334378</td>\n",
       "      <td>0.140295</td>\n",
       "      <td>0.141623</td>\n",
       "      <td>0.075937</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>0.123816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278866</td>\n",
       "      <td>0.137029</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283025</td>\n",
       "      <td>0.366105</td>\n",
       "      <td>0.375922</td>\n",
       "      <td>0.263922</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.146277</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>0.146630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  activation_date  avg_blue  avg_green  avg_red  blurryness  category_name  \\\n",
       "0      2017-03-28       0.0        0.0      0.0         0.0       0.200410   \n",
       "1      2017-03-26       0.0        0.0      0.0         0.0       0.191746   \n",
       "2      2017-03-20       0.0        0.0      0.0         0.0       0.171280   \n",
       "3      2017-03-25       0.0        0.0      0.0         0.0       0.197608   \n",
       "4      2017-03-16       0.0        0.0      0.0         0.0       0.278866   \n",
       "\n",
       "       city                                        description  height  \\\n",
       "0  0.121560  Кокон для сна малыша,пользовались меньше месяц...     0.0   \n",
       "1  0.141313          Стойка для одежды, под вешалки. С бутика.     0.0   \n",
       "2  0.126960  В хорошем состоянии, домашний кинотеатр с blu ...     0.0   \n",
       "3  0.133087                             Продам кресло от0-25кг     0.0   \n",
       "4  0.137029                           Все вопросы по телефону.     0.0   \n",
       "\n",
       "                                               image  ...     param_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...  ...    0.091038   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...  ...    0.123041   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...  ...    0.122309   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...  ...    0.334378   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...  ...    0.283025   \n",
       "\n",
       "    param_2   param_3 parent_category_name    price    region  \\\n",
       "0  0.140372  0.140869             0.076021    400.0  0.121401   \n",
       "1  0.140194  0.138528             0.177335   3000.0  0.138003   \n",
       "2  0.136329  0.139835             0.176872   4000.0  0.136797   \n",
       "3  0.140295  0.141623             0.075937   2200.0  0.142101   \n",
       "4  0.366105  0.375922             0.263922  40000.0  0.146277   \n",
       "\n",
       "                   title       user_id  user_type  width  \n",
       "0  Кокоби(кокон для сна)  e00f8ff2eaf9   0.149016    0.0  \n",
       "1      Стойка для Одежды  39aeb48f0017   0.151873    0.0  \n",
       "2         Philips bluray  91e2f88dd6e3   0.149318    0.0  \n",
       "3             Автокресло  bf5cccea572d   0.123816    0.0  \n",
       "4         ВАЗ 2110, 2003  ef50846afc0b   0.146630    0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(df, image_id, file):\n",
    "    image = Image.open(file)\n",
    "    dat = np.array(image)\n",
    "    #imshow(image)\n",
    "    df.loc[df['image'] == image_id, 'width'] = np.size(dat, 0)\n",
    "    df.loc[df['image'] == image_id, 'height'] =  np.size(dat, 1)\n",
    "    df.loc[df['image'] == image_id, 'img_mean_color'] = np.mean(dat[1].flatten())\n",
    "    df.loc[df['image'] == image_id, 'img_std_color'] = np.std(dat[1].flatten())\n",
    "    average_color = [dat[:, :, i].mean() for i in range(dat.shape[-1])]\n",
    "    df.loc[df['image'] == image_id, 'avg_red'] = average_color[0]/255\n",
    "    df.loc[df['image'] == image_id, 'avg_green'] = average_color[1]/255\n",
    "    df.loc[df['image'] == image_id, 'avg_blue'] = average_color[2]/255\n",
    "    image = cv2.cvtColor(dat, cv2.COLOR_BGR2GRAY)\n",
    "    df.loc[df['image'] == image_id, 'blurryness'] = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Number: 1000\n",
      "Image Number: 2000\n",
      "Image Number: 3000\n",
      "Image Number: 4000\n",
      "Image Number: 5000\n",
      "Image Number: 6000\n",
      "Image Number: 7000\n",
      "Image Number: 8000\n",
      "Image Number: 9000\n",
      "Image Number: 10000\n",
      "Image Number: 11000\n",
      "Image Number: 12000\n",
      "Image Number: 13000\n",
      "Image Number: 14000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dba60252d70b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0minsert_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0minsert_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-dba60252d70b>\u001b[0m in \u001b[0;36minsert_image_features\u001b[0;34m(zipfile)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_in_zip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5cbbdc60fe55>\u001b[0m in \u001b[0;36mget_image_features\u001b[0;34m(df, image_id, file)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img_std_color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0maverage_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_red'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_green'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_blue'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/miniconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_zip = zipfile.ZipFile('/mnt/0d28870f-7d1c-4a10-841a-0195e11cdce3/Jonas/Avito/data/train_jpg.zip', 'r')\n",
    "test_zip = zipfile.ZipFile('/mnt/0d28870f-7d1c-4a10-841a-0195e11cdce3/Jonas/Avito/data/test_jpg.zip', 'r')\n",
    "\n",
    "def insert_image_features(zipfile):\n",
    "    df = test_df\n",
    "    if(zipfile == train_zip):\n",
    "        df = train_df\n",
    "    files_in_zip = zipfile.namelist()\n",
    "    for i,filename in enumerate(files_in_zip):\n",
    "        if filename.endswith('.jpg'):  \n",
    "            if (i%1000 == 0): print(\"Image Number:\", i)\n",
    "            image_id = filename.split('/')[-1].split('.')[0]\n",
    "            if (image_id in df.image.values):\n",
    "                file = zipfile.open(files_in_zip[i])\n",
    "                get_image_features(df, image_id, file)\n",
    "    return\n",
    "        \n",
    "insert_image_features(train_zip)\n",
    "insert_image_features(test_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f9896e2e-8d01-4b00-b7ab-260f384569d8"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine train and test for rest of preprocessing\n",
    "\n",
    "df = pd.concat([train_df,test_df],axis=0)\n",
    "del train_df, test_df\n",
    "gc.collect()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Feature Engineering\n",
    "\n",
    "# Time Data\n",
    "df[\"activation_weekday\"] = df[\"activation_date\"].dt.weekday\n",
    "df[\"activation_monthday\"] = df[\"activation_date\"].dt.day\n",
    "\n",
    "# Price\n",
    "## Replace Nan with mean in price\n",
    "#categories = df.category_name.unique()\n",
    "#region = df.region.unique()\n",
    "#param1 = df.param_1.unique()\n",
    "#\n",
    "#\n",
    "#df[\"price_new\"] = df[\"price\"].values\n",
    "#\n",
    "#for cat in categories:\n",
    "#    for reg in region:\n",
    "#        cur_df = df.loc[(df[\"category_name\"] == cat)  & (df[\"region\"] == reg)][\"price_new\"]\n",
    "#        cur_df.fillna(np.nanmean(cur_df.values), inplace=True)\n",
    "#\n",
    "#\n",
    "#df[\"price\"] = pd.isna(df[\"price\"])\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)\n",
    "df[\"price\"].fillna(-999,inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "\n",
    "#Drop Cols\n",
    "cols_to_drop = [\"item_id\", \"user_id\", \"activation_date\", \"image\"]\n",
    "df.drop(cols_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Features\n",
    "df['text_feat'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['param_1']), \n",
    "    str(row['param_2']), \n",
    "    str(row['param_3'])]),axis=1) # Group Param Features\n",
    "\n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\",\"text_feat\", \"title\"]\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('nicapotato') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols + '_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('text_feat',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('text_feat'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "    \n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.loc[trainindex,:].to_dict('records'))\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "# Drop Text Cols\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = hstack([csr_matrix(df.head(trainindex.shape[0]).values),ready_df[0:trainindex.shape[0]]]) # Sparse Matrix\n",
    "test_X = hstack([csr_matrix(df.tail(testindex.shape[0]).values),ready_df[trainindex.shape[0]:]])\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "for shape in [train_X,test_X]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "26fd8581-09d9-4d0f-b237-005447e59391"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y, feature_name=tfvocab)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y, feature_name=tfvocab)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ca8cb5b5-0e6f-4132-8912-19478b65478b"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data for model training#\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model, evals_result = run_lgb(X_train, y_train, X_val, y_val, test_X)\n",
    "\n",
    "# Making a submission file #\n",
    "pred_test[pred_test>1] = 1\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df = pd.DataFrame({\"item_id\":test_id})\n",
    "sub_df[\"deal_probability\"] = pred_test\n",
    "sub_df.to_csv(\"baseline_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "126a41bb-6e03-476f-ace0-b1ce4b041006"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5bfd3a5f-85c7-41cb-a029-f38f29a4d31f"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35_knime",
   "language": "python",
   "name": "py35_knime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
