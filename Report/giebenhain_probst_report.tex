% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Advanced Data Challenge Seminar\\
		Avito Demand Prediction}
%

% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Simon Giebenhain \and Jonas Probst}
%

% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{University of Konstanz\\
\email{simon.giebenhain@uni-konstanz.de}\\
\email{jonas.probst@uni-konstanz.de}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
This report gives a step-by-step description on how we tackled the Avito Demand Prediction Challenge on Kaggle and gives an overview of the used models, one LightGBM and one Neural Network. The goal of the challenge was to predict 'deal probability' for an advertisement on Avito based on it's parameters. 

\keywords{Kaggle \and Avito \and Demand Prediction \and Data Challenge}
\end{abstract}
%
%
%
\section{Dataset and Data Schema}
\subsection{Dataset}
Kaggle provided the following files for the challenge:
\begin{itemize}
	\item \textbf{train.csv:} Contains approximately 1.5 million training examples.
	\item \textbf{test.csv:} Contains approximately 500 000 test examples.
	\item \textbf{train\_active and test\_active:} Supplemental Data from ads that were displayed in the same time periods.
	\item \textbf{periods\_train and periods\_test:} Supplemental data showing the dates when the ads from train\_active and test\_active were activated and displayed.
	\item \textbf{train\_jpg.zip and test\_jpg.zip:} Images from ads in train.csv and test.csv.
	\item \textbf{sample\_submission.csv:} A sample submission in the correct format.\\
	\begin{center}
	\begin{tabular}{|c|c|}
		\hline 
		\textbf{item\_id} & \textbf{deal\_probability} \\ 
		\hline 
		1 & 0 \\ 
		\hline 
		4 & 0.1 \\ 
		\hline 
		126 & 0.6 \\ 
		\hline 
		... & ... \\ 
		\hline 
	\end{tabular} 
	\end{center} 
\end{itemize}

\subsection{Data Schema}  

Each data sample in train.csv and test.csv corresponds to one advertisement. The features are described in the following table.


\begin{table}
\caption{Data Schema}


\begin{tabular}{|c|c|c|}
	\hline 
	\textbf{Name} & \textbf{Data Type} & \textbf{Description} \\ 
	\hline 
	item\_id & String & Ad ID. \\ 
	\hline 
	user\_id & String & User ID. \\ 
	\hline 
	region & String & Ad region. \\ 
	\hline 
	city & String & Ad city. \\ 
	\hline 
	parent\_category\_name & String & Top level category. \\ 
	\hline 
	category\_name & String & More fine grained category. \\ 
	\hline 
	param\_1 & String & Optional parameter. \\ 
	\hline 
	param\_2 & String & Optional parameter. \\ 
	\hline 
	param\_3 & String & Optional parameter. \\ 
	\hline 
	title & String & Ad title. \\ 
	\hline 
	description & String & Ad description. \\ 
	\hline 
	price & Float & Ad price. \\ 
	\hline 
	item\_seq\_number & Integer & Ad seqential number for user. \\ 
	\hline 
	activation\_date & Date & Date ad was placed. \\ 
	\hline 
	user\_type & String & User type (Private, Company or Shop) \\ 
	\hline 
	image & String & ID of image. Same as filename. \\ 
	\hline 
	image\_top\_1 & Float & Mystery classification code for image. \\ 
	\hline 
	deal\_probability & Float & \begin{tabular}[c]{@{}c@{}}Target variable.\\ The likelihood that an ad actually sold something. \\No information on how it got calculated.\end{tabular} \\ 
	\hline 
\end{tabular} 
\end{table}

\section{Data Preprocessing}
\subsection{Data Preprocessing for LightGBM}
\subsubsection{Categorical Features:}
LightGBM only works on numerical data, so categorical data needs to be encoded. We used target encoding on "region", "city", "parent\_category\_name", "category\_name", "user\_type", "param\_1", "param\_2", "param\_3", "image\_top\_1".\\
Target encoding replaces the original value with the mean of the target variable value of all columns with the same original value.
\subsubsection{Numerical Features:}
Because you can sell anything from clothes to houses on Avito, "price" has a huge range, so we scaled it logarithmically.\\
The other numerical features did not need to be preprocessed.
\subsubsection{Activaton Date:} 
We extracted the weekday from "activation\_date" as a number from 0 to 6 and just kept that number, because month or day in month did not repeat.

\subsubsection{Missing Values}
 For most columns there are no missing values, because they are mandatory to fill in for uploading an ad or get filled in automatically. "param\_2" and "param\_3" have about 50\% missing values, because they are optional or don't exist for some categories. The Description was empty in about 8\%. We filled all these missing values with the empty string, as there is no good way to approximate these values and it may not even be desired because having no description is an interesting information itself.\\ \\
 Image and "image\_top\_1" were also missing in about 8\% of ads, which simply were uploaded without image. Here we actually trained a neural network on the description, title and optional parameters for ads with images to predict "image\_top\_1" because it was such an important variable.\\ \\
 Price is missing for about 5\%  of ads. There could be multiple reasons for that, for example the price could just be written in the description, could be up for debate our could depend on the amount one wants to buy. So we replaced missing values with -1, because setting it to zero would imply that the item was put up for free.

\end{document}