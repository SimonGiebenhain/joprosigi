{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e2195128-b796-44fd-8edb-beb09941d8fc"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import target_encoding as te\n",
    "import gc\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "import time\n",
    "\n",
    "#Images\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "4cc55424-87d6-4f00-89d9-a51982dd1ff3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file rows and columns are :  (1503424, 18)\n",
      "Test file rows and columns are :  (508438, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/home/jonas/Documents/Uni/DataChallenge/train.csv\", parse_dates=[\"activation_date\"])#, nrows=1000)\n",
    "test_df = pd.read_csv(\"/home/jonas/Documents/Uni/DataChallenge/test.csv\", parse_dates=[\"activation_date\"])#, nrows=1000)\n",
    "trainindex = train_df.index\n",
    "testindex = test_df.index\n",
    "test_id = test_df[\"item_id\"].values\n",
    "print(\"Train file rows and columns are : \", train_df.shape)\n",
    "print(\"Test file rows and columns are : \", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_df.deal_probability.copy()\n",
    "train_df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "train_df['param_1_enc'] = train_df['param_1']\n",
    "train_df['param_2_enc'] = train_df['param_2']\n",
    "train_df['param_3_enc'] = train_df['param_3']\n",
    "test_df['param_1_enc'] = test_df['param_1']\n",
    "test_df['param_2_enc'] = test_df['param_2']\n",
    "test_df['param_3_enc'] = test_df['param_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1_enc\", \"param_2_enc\", \"param_3_enc\", \"image_top_1\"]\n",
    "for col in cat_vars:\n",
    "    train_df[col], test_df[col] = te.target_encode(train_df[col], test_df[col], train_y, min_samples_leaf=100, smoothing=10, noise_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "f9896e2e-8d01-4b00-b7ab-260f384569d8"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>param_1_enc</th>\n",
       "      <th>param_2_enc</th>\n",
       "      <th>param_3_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>0.121034</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>0.075071</td>\n",
       "      <td>0.197015</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>0.147915</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>0.090174</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.139078</td>\n",
       "      <td>0.137243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>0.135664</td>\n",
       "      <td>0.139539</td>\n",
       "      <td>0.179820</td>\n",
       "      <td>0.190341</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>0.148545</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>0.160086</td>\n",
       "      <td>0.124415</td>\n",
       "      <td>0.141273</td>\n",
       "      <td>0.138741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>0.138754</td>\n",
       "      <td>0.124479</td>\n",
       "      <td>0.177953</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>0.152046</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>0.198515</td>\n",
       "      <td>0.121522</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>0.137097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>0.144961</td>\n",
       "      <td>0.135243</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.198891</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>0.124238</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>0.332232</td>\n",
       "      <td>0.329946</td>\n",
       "      <td>0.141783</td>\n",
       "      <td>0.139828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>0.147332</td>\n",
       "      <td>0.137236</td>\n",
       "      <td>0.264195</td>\n",
       "      <td>0.273961</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>0.151996</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>0.320642</td>\n",
       "      <td>0.285478</td>\n",
       "      <td>0.358954</td>\n",
       "      <td>0.378998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id    region      city  parent_category_name  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9  0.121034  0.122642              0.075071   \n",
       "1  2dac0150717d  39aeb48f0017  0.135664  0.139539              0.179820   \n",
       "2  ba83aefab5dc  91e2f88dd6e3  0.138754  0.124479              0.177953   \n",
       "3  02996f1dd2ea  bf5cccea572d  0.144961  0.135243              0.075700   \n",
       "4  7c90be56d2ab  ef50846afc0b  0.147332  0.137236              0.264195   \n",
       "\n",
       "   category_name                      param_1     param_2 param_3  \\\n",
       "0       0.197015    Постельные принадлежности         NaN     NaN   \n",
       "1       0.190341                       Другое         NaN     NaN   \n",
       "2       0.169517  Видео, DVD и Blu-ray плееры         NaN     NaN   \n",
       "3       0.198891         Автомобильные кресла         NaN     NaN   \n",
       "4       0.273961                   С пробегом  ВАЗ (LADA)    2110   \n",
       "\n",
       "                   title                                        description  \\\n",
       "0  Кокоби(кокон для сна)  Кокон для сна малыша,пользовались меньше месяц...   \n",
       "1      Стойка для Одежды          Стойка для одежды, под вешалки. С бутика.   \n",
       "2         Philips bluray  В хорошем состоянии, домашний кинотеатр с blu ...   \n",
       "3             Автокресло                             Продам кресло от0-25кг   \n",
       "4         ВАЗ 2110, 2003                           Все вопросы по телефону.   \n",
       "\n",
       "     price  item_seq_number activation_date  user_type  \\\n",
       "0    400.0                2      2017-03-28   0.147915   \n",
       "1   3000.0               19      2017-03-26   0.148545   \n",
       "2   4000.0                9      2017-03-20   0.152046   \n",
       "3   2200.0              286      2017-03-25   0.124238   \n",
       "4  40000.0                3      2017-03-16   0.151996   \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...     0.090174   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...     0.160086   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...     0.198515   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...     0.332232   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...     0.320642   \n",
       "\n",
       "   param_1_enc  param_2_enc  param_3_enc  \n",
       "0     0.091922     0.139078     0.137243  \n",
       "1     0.124415     0.141273     0.138741  \n",
       "2     0.121522     0.142401     0.137097  \n",
       "3     0.329946     0.141783     0.139828  \n",
       "4     0.285478     0.358954     0.378998  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine train and test for preprocessing\n",
    "\n",
    "df = pd.concat([train_df,test_df],axis=0)\n",
    "del train_df, test_df\n",
    "gc.collect()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple Feature Engineering\n",
    "\n",
    "# Time Data\n",
    "df[\"activation_weekday\"] = df[\"activation_date\"].dt.weekday\n",
    "df[\"activation_monthday\"] = df[\"activation_date\"].dt.day\n",
    "\n",
    "# Price\n",
    "## Replace Nan with mean in price\n",
    "#categories = df.category_name.unique()\n",
    "#region = df.region.unique()\n",
    "#param1 = df.param_1.unique()\n",
    "#\n",
    "#\n",
    "#df[\"price_new\"] = df[\"price\"].values\n",
    "#\n",
    "#for cat in categories:\n",
    "#    for reg in region:\n",
    "#        cur_df = df.loc[(df[\"category_name\"] == cat)  & (df[\"region\"] == reg)][\"price_new\"]\n",
    "#        cur_df.fillna(np.nanmean(cur_df.values), inplace=True)\n",
    "#\n",
    "#\n",
    "#df[\"price\"] = pd.isna(df[\"price\"])\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)\n",
    "df[\"price\"].fillna(-999,inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "\n",
    "#Drop Cols\n",
    "cols_to_drop = [\"item_id\", \"user_id\", \"activation_date\", \"image\"]\n",
    "df.drop(cols_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image Featues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Features\n",
    "df['text_feat'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['param_1']), \n",
    "    str(row['param_2']), \n",
    "    str(row['param_3'])]),axis=1) # Group Param Features\n",
    "\n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\",\"text_feat\", \"title\"]\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('nicapotato') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols + '_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      постельные принадлежности nan nan\n",
       "1                         другое nan nan\n",
       "2    видео, dvd и blu-ray плееры nan nan\n",
       "3           автомобильные кресла nan nan\n",
       "4             с пробегом ваз (lada) 2110\n",
       "Name: text_feat, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_feat'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/py35_knime/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "out_df = df.head(trainindex.shape[0])\n",
    "out_df['deal_probability']= train_y\n",
    "out_df.head()\n",
    "out_df.to_csv('dataframe_text_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('text_feat',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('text_feat'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "    \n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.loc[trainindex,:].to_dict('records'))\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "# Drop Text Cols\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = hstack([csr_matrix(df.head(trainindex.shape[0]).values),ready_df[0:trainindex.shape[0]]]) # Sparse Matrix\n",
    "test_X = hstack([csr_matrix(df.tail(testindex.shape[0]).values),ready_df[trainindex.shape[0]:]])\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "for shape in [train_X,test_X]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "26fd8581-09d9-4d0f-b237-005447e59391"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y, feature_name=tfvocab)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y, feature_name=tfvocab)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ca8cb5b5-0e6f-4132-8912-19478b65478b"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data for model training#\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model, evals_result = run_lgb(X_train, y_train, X_val, y_val, test_X)\n",
    "\n",
    "# Making a submission file #\n",
    "pred_test[pred_test>1] = 1\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df = pd.DataFrame({\"item_id\":test_id})\n",
    "sub_df[\"deal_probability\"] = pred_test\n",
    "sub_df.to_csv(\"baseline_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "126a41bb-6e03-476f-ace0-b1ce4b041006"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5bfd3a5f-85c7-41cb-a029-f38f29a4d31f"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35_knime]",
   "language": "python",
   "name": "conda-env-py35_knime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
