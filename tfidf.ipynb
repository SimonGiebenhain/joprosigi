{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e2195128-b796-44fd-8edb-beb09941d8fc"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import target_encoding as te\n",
    "import gc\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "import time\n",
    "\n",
    "#Images\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "4cc55424-87d6-4f00-89d9-a51982dd1ff3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file rows and columns are :  (1503424, 18)\n",
      "Test file rows and columns are :  (508438, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\", parse_dates=[\"activation_date\"], nrows=1000)\n",
    "test_df = pd.read_csv(\"../data/test.csv\", parse_dates=[\"activation_date\"], nrows=1000)\n",
    "#periods_train = pd.read_csv(\"../data/periods_train.csv\", parse_dates=[\"activation_date\", \"date_from\", \"date_to\"])#, nrows=1000)\n",
    "#periods_test = pd.read_csv(\"../data/periods_test.csv\", parse_dates=[\"activation_date\", \"date_from\", \"date_to\"])#, nrows=1000)\n",
    "#train_active = pd.read_csv(\"../data/train_active.csv\", parse_dates=[\"activation_date\"], nrows=1000)\n",
    "#test_active = pd.read_csv(\"../data/test_active.csv\", parse_dates=[\"activation_date\"], nrows=1000)\n",
    "trainindex = train_df.index\n",
    "testindex = test_df.index\n",
    "test_id = test_df[\"item_id\"].values\n",
    "print(\"Train file rows and columns are : \", train_df.shape)\n",
    "print(\"Test file rows and columns are : \", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_df.deal_probability.copy()\n",
    "train_df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "train_df['param_1_enc'] = train_df['param_1']\n",
    "train_df['param_2_enc'] = train_df['param_2']\n",
    "train_df['param_3_enc'] = train_df['param_3']\n",
    "test_df['param_1_enc'] = test_df['param_1']\n",
    "test_df['param_2_enc'] = test_df['param_2']\n",
    "test_df['param_3_enc'] = test_df['param_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate concurrent offers\n",
    "#def calc_conc(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1_enc\", \"param_2_enc\", \"param_3_enc\", \"image_top_1\"]\n",
    "for col in cat_vars:\n",
    "    train_df[col], test_df[col] = te.target_encode(train_df[col], test_df[col], train_y, min_samples_leaf=100, smoothing=10, noise_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "f9896e2e-8d01-4b00-b7ab-260f384569d8"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'periods_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a70579822c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Combine train and test for preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiods_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiods_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'periods_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine train and test for preprocessing\n",
    "df = pd.concat([train_df,test_df],axis=0)\n",
    "del train_df, test_df, periods_train, periods_test\n",
    "gc.collect()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple Feature Engineering\n",
    "\n",
    "# Time Data\n",
    "df[\"activation_weekday\"] = df[\"activation_date\"].dt.weekday\n",
    "df[\"activation_monthday\"] = df[\"activation_date\"].dt.day\n",
    "\n",
    "# Price\n",
    "## Replace Nan with mean in price\n",
    "#categories = df.category_name.unique()\n",
    "#region = df.region.unique()\n",
    "#param1 = df.param_1.unique()\n",
    "#\n",
    "#\n",
    "#df[\"price_new\"] = df[\"price\"].values\n",
    "#\n",
    "#for cat in categories:\n",
    "#    for reg in region:\n",
    "#        cur_df = df.loc[(df[\"category_name\"] == cat)  & (df[\"region\"] == reg)][\"price_new\"]\n",
    "#        cur_df.fillna(np.nanmean(cur_df.values), inplace=True)\n",
    "#\n",
    "#\n",
    "#df[\"price\"] = pd.isna(df[\"price\"])\n",
    "df[\"price\"] = np.log(df[\"price\"]+1)\n",
    "df[\"price\"].fillna(0, inplace=True)\n",
    "df[\"image_top_1\"].fillna(0, inplace=True)\n",
    "df['param_1'].fillna(\"\", inplace = True)\n",
    "df['param_2'].fillna(\"\", inplace = True)\n",
    "df['param_3'].fillna(\"\", inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "#Drop Cols\n",
    "cols_to_drop = [\"item_id\", \"user_id\", \"activation_date\", \"image\"]\n",
    "df.drop(cols_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>param_1_enc</th>\n",
       "      <th>param_2_enc</th>\n",
       "      <th>param_3_enc</th>\n",
       "      <th>activation_weekday</th>\n",
       "      <th>activation_monthday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121320</td>\n",
       "      <td>0.123533</td>\n",
       "      <td>0.075998</td>\n",
       "      <td>0.201166</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>5.993961</td>\n",
       "      <td>2</td>\n",
       "      <td>0.149540</td>\n",
       "      <td>0.090331</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>0.139320</td>\n",
       "      <td>0.139232</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.135914</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>0.178592</td>\n",
       "      <td>0.192418</td>\n",
       "      <td>Другое</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>8.006701</td>\n",
       "      <td>19</td>\n",
       "      <td>0.151302</td>\n",
       "      <td>0.158886</td>\n",
       "      <td>0.127686</td>\n",
       "      <td>0.139361</td>\n",
       "      <td>0.138138</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135907</td>\n",
       "      <td>0.125005</td>\n",
       "      <td>0.173680</td>\n",
       "      <td>0.170787</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>8.294300</td>\n",
       "      <td>9</td>\n",
       "      <td>0.149191</td>\n",
       "      <td>0.202160</td>\n",
       "      <td>0.121040</td>\n",
       "      <td>0.140071</td>\n",
       "      <td>0.139185</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.135035</td>\n",
       "      <td>0.075804</td>\n",
       "      <td>0.197715</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>7.696667</td>\n",
       "      <td>286</td>\n",
       "      <td>0.124252</td>\n",
       "      <td>0.335410</td>\n",
       "      <td>0.334184</td>\n",
       "      <td>0.139328</td>\n",
       "      <td>0.140310</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144486</td>\n",
       "      <td>0.139964</td>\n",
       "      <td>0.265420</td>\n",
       "      <td>0.275890</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>10.596660</td>\n",
       "      <td>3</td>\n",
       "      <td>0.149236</td>\n",
       "      <td>0.318774</td>\n",
       "      <td>0.284435</td>\n",
       "      <td>0.362017</td>\n",
       "      <td>0.371570</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     region      city  parent_category_name  category_name  \\\n",
       "0  0.121320  0.123533              0.075998       0.201166   \n",
       "1  0.135914  0.140094              0.178592       0.192418   \n",
       "2  0.135907  0.125005              0.173680       0.170787   \n",
       "3  0.143072  0.135035              0.075804       0.197715   \n",
       "4  0.144486  0.139964              0.265420       0.275890   \n",
       "\n",
       "                       param_1     param_2 param_3                  title  \\\n",
       "0    Постельные принадлежности                      Кокоби(кокон для сна)   \n",
       "1                       Другое                          Стойка для Одежды   \n",
       "2  Видео, DVD и Blu-ray плееры                             Philips bluray   \n",
       "3         Автомобильные кресла                                 Автокресло   \n",
       "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
       "\n",
       "                                         description      price  \\\n",
       "0  Кокон для сна малыша,пользовались меньше месяц...   5.993961   \n",
       "1          Стойка для одежды, под вешалки. С бутика.   8.006701   \n",
       "2  В хорошем состоянии, домашний кинотеатр с blu ...   8.294300   \n",
       "3                             Продам кресло от0-25кг   7.696667   \n",
       "4                           Все вопросы по телефону.  10.596660   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1  param_1_enc  param_2_enc  \\\n",
       "0                2   0.149540     0.090331     0.089624     0.139320   \n",
       "1               19   0.151302     0.158886     0.127686     0.139361   \n",
       "2                9   0.149191     0.202160     0.121040     0.140071   \n",
       "3              286   0.124252     0.335410     0.334184     0.139328   \n",
       "4                3   0.149236     0.318774     0.284435     0.362017   \n",
       "\n",
       "   param_3_enc  activation_weekday  activation_monthday  \n",
       "0     0.139232                   1                   28  \n",
       "1     0.138138                   6                   26  \n",
       "2     0.139185                   0                   20  \n",
       "3     0.140310                   5                   25  \n",
       "4     0.371570                   3                   16  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Featues\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text Features\n",
    "df['text_feat'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['param_1']), \n",
    "    str(row['param_2']), \n",
    "    str(row['param_3'])]),axis=1) # Group Param Features\n",
    "\n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\",\"text_feat\", \"title\"]\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('empty') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols + '_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      постельные принадлежности  \n",
       "1                         другое  \n",
       "2    видео, dvd и blu-ray плееры  \n",
       "3           автомобильные кресла  \n",
       "4       с пробегом ваз (lada) 2110\n",
       "Name: text_feat, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/py35_knime/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "out_df = df.head(trainindex.shape[0])\n",
    "out_df['deal_probability']= train_y\n",
    "out_df.head()\n",
    "out_df.to_csv('dataframe_text_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF] Term Frequency Inverse Document Frequency Stage\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c2bb6f49af2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mstart_vect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mready_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtfvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self, orient, into)\u001b[0m\n\u001b[1;32m    999\u001b[0m             return [into_c((k, _maybe_box_datetimelike(v))\n\u001b[1;32m   1000\u001b[0m                            for k, v in zip(self.columns, np.atleast_1d(row)))\n\u001b[0;32m-> 1001\u001b[0;31m                     for row in self.values]\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minto_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    999\u001b[0m             return [into_c((k, _maybe_box_datetimelike(v))\n\u001b[1;32m   1000\u001b[0m                            for k, v in zip(self.columns, np.atleast_1d(row)))\n\u001b[0;32m-> 1001\u001b[0;31m                     for row in self.values]\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minto_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             return [into_c((k, _maybe_box_datetimelike(v))\n\u001b[0;32m-> 1000\u001b[0;31m                            for k, v in zip(self.columns, np.atleast_1d(row)))\n\u001b[0m\u001b[1;32m   1001\u001b[0m                     for row in self.values]\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35_knime/lib/python3.5/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_maybe_box_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# turn a datetime like into a Timestamp/timedelta as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtslib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('text_feat',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('text_feat'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "    \n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.loc[trainindex,:].to_dict('records'))\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "# Drop Text Cols\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = hstack([csr_matrix(df.head(trainindex.shape[0]).values),ready_df[0:trainindex.shape[0]]]) # Sparse Matrix\n",
    "test_X = hstack([csr_matrix(df.tail(testindex.shape[0]).values),ready_df[trainindex.shape[0]:]])\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "for shape in [train_X,test_X]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "26fd8581-09d9-4d0f-b237-005447e59391"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y, feature_name=tfvocab)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y, feature_name=tfvocab)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ca8cb5b5-0e6f-4132-8912-19478b65478b"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data for model training#\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model, evals_result = run_lgb(X_train, y_train, X_val, y_val, test_X)\n",
    "\n",
    "# Making a submission file #\n",
    "pred_test[pred_test>1] = 1\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df = pd.DataFrame({\"item_id\":test_id})\n",
    "sub_df[\"deal_probability\"] = pred_test\n",
    "sub_df.to_csv(\"baseline_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "126a41bb-6e03-476f-ace0-b1ce4b041006"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5bfd3a5f-85c7-41cb-a029-f38f29a4d31f"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35_knime]",
   "language": "python",
   "name": "conda-env-py35_knime-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
